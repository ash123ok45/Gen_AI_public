Q1. 
 Your company's marketing team wants to generate product descriptions automatically. They are debating between using a traditional rule-based system that follows templates or a generative AI model. What is the key difference that makes GenAI more suitable for this creative task?

a) Traditional AI processes data faster than GenAI
b) GenAI can create new, original content while traditional AI follows predefined rules
c) Traditional AI is more accurate than GenAI
d) GenAI requires less computational power

Correct Answer: b  
Explanation: The fundamental difference is that GenAI can create new, original content by learning patterns from training data, while traditional AI follows predefined rules and templates without genuine creativity.


Q2.Your startup has limited hardware but wants to use AI for sentiment analysis. Why might cloud AI be preferred over local AI? 
a) It requires expensive local servers
b) It offers access to powerful, scalable computing resources
c) It limits model customization
d) It depends on local storage 

Correct Answer: b 
Explanation: Cloud AI provides scalable computing resources, making it cost-effective for startups without heavy hardware investments, unlike local AI, which needs robust on-site systems.

Q3.You are selecting an LLM for a project where you need to modify its code. What is a key feature of an open-source LLM compared to a closed LLM?
a) It allows access to code, model to be downloaded & community-driven modifications 
b) It restricts access to its code 
c) It is always hosted in the cloud 
d) It requires no API keys
 
Correct Answer: a
Explanation: Open-source LLMs have publicly available code, enabling community modifications and customization, unlike closed LLMs, which restrict code access.

Q4. Q5. Scenario: A startup wants to integrate ChatGPT into their app. What is the first step they should take?  
a) Download the model weights 
b) Train a custom model   
c) Purchase API keys from OpenAI  
d) Use a no-code platform  
Correct Answer: c 
Explanation: To use closed AI models like ChatGPT, developers must obtain API keys from the provider, which often involves purchasing access.  

Q5. Which command pulls the 'bert-base-uncased' model from Hugging Face?  
a) pip install bert-base-uncased  
b) from transformers import BertModel  
c) ollama pull bert-base-uncased  
d) Both b and c  
Correct Answer: d  
Explanation: Option b imports the model using Hugging Face's transformers library, while option c uses Ollama's CLI for local deployment. Both are valid methods.  

Q6.A hospital wants to process patient data on-site due to privacy laws. Which approach aligns with this constraint?  
a) Cloud-based AI like OpenAI’s API  
b) Local AI model hosted on internal servers  
c) Hybrid model with data sent to third-party servers  
d) Public Hugging Face inference endpoints  
Correct Answer: b  
Explanation: Local AI ensures data stays on-premises, critical for privacy-sensitive domains like healthcare.  

Q7.Your analyst must explore 3,000 PDFs without coding. Which two Hugging Face Spaces capabilities together are most helpful? (Select two)
    a) RAG‑based document Q&A Space
    b) Stable Diffusion image generator
    c) WhisperX transcription Space
    d) Tokeniser visualiser Space

Correct Answer: a, c
Explanation: Transcribing audio (if any) with WhisperX and querying text via RAG Q&A empower no‑code PDF exploration; image generation and token visualisation are irrelevant here.

Q8.A data scientist wants to create an interactive demo of their machine learning model for stakeholders. They need a platform that allows easy deployment without complex setup. Which platform would be most appropriate?

a) Traditional web hosting services
b) HuggingFace Spaces
c) Local server deployment
d) Email-based sharing

Correct Answer: b  
Explanation: HuggingFace Spaces provides an easy-to-use platform for deploying interactive ML demos with various frameworks (Streamlit, Gradio) without complex infrastructure setup.

Q9. In prompt engineering, a "prompt" is best defined as:  
a) A pre-trained model  
b) Input instructions/data/context given to an AI model  
c) The output generated by an LLM  
d) A fine-tuning dataset  
Correct Answer: b  
Explanation: Prompts are user-provided inputs guiding AI responses.  

Q10.  You ask an LLM to translate "Hello" to French without examples. This demonstrates:  
a) Few-shot learning  
b) Zero-shot learning  
c) Chain-of-Thought prompting  
d) Instruction tuning  
Correct Answer: b  
Explanation: Zero-shot tasks require no examples; the model relies on pre-trained knowledge.  

Q11. You try zero‑shot prompting for product descriptions but output quality is low. Which TWO actions align with *few‑shot* strategy to improve results? (Select two)
    a) Append two labelled examples before the actual prompt
    b) Increase max_tokens parameter only
    c) Reduce temperature to zero
    d) Provide a negative example of what **not** to write
Correct Answer: a, d
Explanation: Few‑shot adds positive and even negative examples to steer style; token limits and temperature alone are insufficient for few‑shot gains.

Q12.A marketing manager wants an AI to write product descriptions but keeps getting generic outputs. What is the most fundamental element they should focus on first to improve their prompts?

a) Making the prompt as long as possible
b) Clearly defining the Role, Task, and Context
c) Using technical jargon to sound professional
d) Asking for multiple variations simultaneously

Correct Answer: b  
Explanation: The R+T+C foundation (Role, Task, Context) is essential for clear communication with AI, providing the necessary framework for specific, relevant outputs.

Q13.You're asking an AI to solve a complex business problem about market entry strategy. Instead of asking for a direct answer, you prompt it to "think through this step by step, considering market research, competitive analysis, and risk assessment." Which advanced technique are you using?

a) Tree of Thought (ToT)
b) Chain of Thought (CoT)
c) ReAct prompting
d) Prompt chaining

Correct Answer: b  
Explanation: Chain of Thought (CoT) prompting encourages the AI to break down complex problems into sequential steps, showing its reasoning process.

Q14.A new prompt engineer is struggling with inconsistent AI outputs. They write: "Write something about dogs." What is the primary issue with this prompt?

a) It's too short
b) It lacks specific Role, Task, and Context
c) It doesn't mention the output format
d) It's too simple for AI to understand

Correct Answer: b  
Explanation: The prompt lacks essential elements: no defined role for the AI, vague task description, and no context about purpose, audience, or requirements, leading to inconsistent outputs.

Q15. A trainee mixes up *Prompt Engineering* with model fine‑tuning. Which statement correctly distinguishes them?
    a) Prompt engineering rewrites the training dataset
    b) Fine‑tuning alters model weights; prompting leaves weights untouched and focuses on input crafting
    c) Both always require GPU training time
    d) Prompt engineering is only for closed models
Correct Answer: b
Explanation: Prompt engineering shapes outputs by designing inputs, whereas fine‑tuning changes internal weights.

Q16. To improve response accuracy, you should: (Select all that apply)  
a) Use ambiguous language  
b) Specify output format (e.g., JSON)  
c) Break complex tasks into steps  
d) Avoid context limitations  
Correct Answer: b, c  
Explanation: Clear output formats and task decomposition enhance precision.

Q17.A content team wants to create a multi-step workflow where one AI generates a blog outline, another writes the content, and a third optimises it for SEO. What advanced technique would orchestrate this process?

a) Single complex prompt
b) Chain of Thought prompting
c) Prompt chaining
d) Few-shot prompting

Correct Answer: c  
Explanation: Prompt chaining connects multiple prompts in sequence, where the output of one prompt becomes the input for the next, creating complex workflows.

Q18. Which code snippet demonstrates Chain of Thought (CoT) prompting?  
a) "Solve 2+2"  
b) "Step 1: Add 2 and 2. Step 2: The result is 4."  
c) "Answer: 4"  
d) "Calculate 2+2"  
Correct Answer: b  
Explanation: CoT involves explicit reasoning steps before the final answer.

Q19.A company wants to adapt an LLM for legal document analysis. What is the most efficient method?  
a) Full retraining from scratch  
b) Instruction tuning with domain-specific data  
c) Using the model as-is  
d) Switching to a different model  
Correct Answer: b  
Explanation: Instruction tuning involves fine-tuning the model with task-specific data to specialize it for particular applications without full retraining. 

Q20.You are designing a prompt for a chatbot using the R+T+C+F+R formula. Which components are included in this formula?
a) Role, Task, Context, FewShot, Report
b) Role, Task, Database, FewShot, Storage
c) Role, Hardware, Context, Report, Data 
d) Task, Algorithm, Context, FewShot, Code
 Correct Answer: a 
Explanation: The R+T+C+F+R formula includes Role (e.g., “act as a chatbot”), Task (e.g., “respond to queries”), Context (e.g., “for a retail store”), FewShot (examples), and Report (output format), ideal for structuring prompts.
